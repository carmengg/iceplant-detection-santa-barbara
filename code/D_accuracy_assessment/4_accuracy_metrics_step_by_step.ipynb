{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "This is a notebook for calculating the following statistics in a map:\n",
    "- producer's accuracies and user's accuracies by class,\n",
    "- overall accuracy, and\n",
    "- area estimates. \n",
    "\n",
    "Each statistic is accompanied by a 95% confidence interval. \n",
    "To do this, we follow the notation and calculations in Olofsson et al..\n",
    "\n",
    "The data input needs to be:\n",
    "1. a csv of the points assessed with two columns: map_class and ref_class. Map class is the classification of the point in the map, ref_class is the \"ground truth\" classification of the point. \n",
    "\n",
    "2. a csv with the number of pixels per class in the map.\n",
    "\n",
    "## Reference\n",
    "\n",
    "Pontus Olofsson, Giles M. Foody, Martin Herold, Stephen V. Stehman, Curtis E. Woodcock, Michael A. Wulder, Good practices for estimating area and assessing accuracy of land change, Remote Sensing of Environment,Volume 148, 2014, Pages 42-57, ISSN 0034-4257, https://doi.org/10.1016/j.rse.2014.02.015.  (https://www.sciencedirect.com/science/article/pii/S0034425714000704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# Assuming repository's parent directory is the home directory\n",
    "home = os.path.expanduser(\"~\")\n",
    "os.chdir(os.path.join(home,'iceplant-detection-santa-barbara'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "To run the example in Olofsson et al., do not import any data and do not execute the cells in this section. \n",
    "Instead, go to the next section and execute the cell having the Olofsson et al. data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120173466,   5981423, 188071487])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'final_model'\n",
    "validation_data_dir = os.path.join(os.getcwd(),\n",
    "                              'data',\n",
    "                              'map',\n",
    "                              'validation_data')\n",
    "# load csv with validation points\n",
    "df = pd.read_csv(os.path.join(validation_data_dir,\n",
    "                              prefix+'_map_and_reference_classes.csv'))\n",
    "\n",
    "# specify number of classes in the map\n",
    "n_classes = 3\n",
    "\n",
    "#load counts of pixels per class in map\n",
    "pixel_count_path = os.path.join(validation_data_dir,\n",
    "                              'pixel_counts',\n",
    "                                prefix+'_combined_pixel_counts_total.csv')\n",
    "pix_counts = pd.read_csv(pixel_count_path)\n",
    "pix_counts = pix_counts.to_numpy()[0]\n",
    "pix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in each reference class\n",
      "(array([0, 1, 2]), array([321, 264, 404])) \n",
      "\n",
      "Points in each map class\n",
      "(array([0, 1, 2]), array([289, 296, 404]))\n"
     ]
    }
   ],
   "source": [
    "# counts by reference class\n",
    "print('Points in each reference class')\n",
    "print(np.unique(df.ref_class, return_counts=True), '\\n')\n",
    "\n",
    "# counts by map class: these should match the counts given by the stratified sample design\n",
    "print('Points in each map class')\n",
    "print(np.unique(df.map_class, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Here we create a confusion matrix $n$ such that \n",
    "\n",
    "$n_{i,j}$ = number of points predicted as $i$, known to be $j$, \n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$n_{i,j}$ = number of points that have map class as $i$ and reference class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[247,   2,  40],\n",
       "       [ 26, 262,   8],\n",
       "       [ 48,   0, 356]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CALCULATE CONFUSION MATRIX FOR IMPORTED DATA\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# using confusion_matrix directly we get a matrix C such that\n",
    "# C_{i,j} = known to be i, predicted as  j \n",
    "# The notation in the paper is \n",
    "# n_{i,j} = predicted as i, known to be j \n",
    "# so we need to take the transpose\n",
    "\n",
    "n = confusion_matrix(df.ref_class, df.map_class, labels=range(n_classes)).T\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user's accuracies: [85.46712802768167, 88.51351351351352, 88.11881188118812]\n",
      "user's accuracies confidence interval: [4.04961416 3.62011191 3.14301418]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# points in sample that had class i in map (predicted as i, any true class j)\n",
    "# these will also be used in overal accuracy and producer's accuracies\n",
    "n_idot = [sum(n[i,:]) for i in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# estimated users' accuracy (precision for each class: TP/(TP+FP))\n",
    "U_hat = [n[i,i] / n_idot[i] for i in range(n_classes)]\n",
    "\n",
    "var_U_hat = [U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "print(\"user's accuracies:\", [x*100 for x in U_hat])\n",
    "print(\"user's accuracies confidence interval:\", 1.95*np.sqrt(var_U_hat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overal Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 87.11220904276064\n",
      "overall accuracy confidence interval: 2.4376493210335597 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total number of pixels in the map\n",
    "total_pix = sum(pix_counts)\n",
    "\n",
    "# list with the fractions of area in map mapped as each class\n",
    "W = [pix_counts[i]/ total_pix for i in range(n_classes)]      \n",
    "\n",
    "# -------------------------------------\n",
    "# overall accuracy\n",
    "O_hat = sum([W[i]*n[i,i]/n_idot[i] for i in range(n_classes)])\n",
    "print('overall accuracy:', O_hat*100)\n",
    "\n",
    "# -------------------------------------\n",
    "var_O_hat = sum([ W[i]**2 * U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(n_classes)])\n",
    "\n",
    "# std error of estimated overall accuracy\n",
    "print('overall accuracy confidence interval:', 1.95*np.sqrt(var_O_hat)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer's accuracies: [81.78798853172489, 86.42429238701436, 90.79850351390348]\n",
      "producer's accuracies confidence interval: [ 3.91598154 16.15675927  2.39143534] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_hat_dotj = []\n",
    "# estimated producer's accuracy (sensitiviy for each class TP/(TP+FN))\n",
    "P_hat = []  \n",
    "\n",
    "for j in range(n_classes):\n",
    "    # list of p_hat_ij with fixed j\n",
    "    p_hat_ij = [ W[i]*n[i,j]/n_idot[i] for i in range(n_classes) ]\n",
    "    p_hat_dotj.append(sum(p_hat_ij))  # equation (9)\n",
    "\n",
    "\n",
    "P_hat= [ (W[j]*n[j,j]/n_idot[j]) / p_hat_dotj[j] for j in range(n_classes)]\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies:\", [x*100 for x in P_hat])\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "# VARIANCE\n",
    "# notice N_jdot is pixel_counts[j]\n",
    "N_hat_cdotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ pix_counts[i] * n[i,j]/n_idot[i] for i in range(n_classes)]\n",
    "    N_hat_cdotj.append(sum(summands))\n",
    "\n",
    "# -------------------------------------\n",
    "summand1 = [ (pix_counts[j]**2) * ((1-P_hat[j])**2) * U_hat[j] * (1-U_hat[j]) / (n_idot[j] - 1) \n",
    "            for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "summand2 = []\n",
    "for j in range(n_classes):\n",
    "    inner = []\n",
    "    for i in range(n_classes):\n",
    "        if i!=j:\n",
    "            inner.append( (pix_counts[i]**2) /(n_idot[i]-1) * (n[i,j])/(n_idot[i]) * ( 1 - n[i,j]/n_idot[i]) ) \n",
    "    summand2.append((P_hat[j]**2) * sum(inner))\n",
    "\n",
    "# -------------------------------------\n",
    "var_P_hat = [1/(N_hat_cdotj[j]**2) *  (summand1[j] + summand2[j]) for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies confidence interval:\", 1.95*np.sqrt(var_P_hat)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Area Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of area per class: \n",
      " [39.96460579533045, 1.9495556092790984, 58.08583859539045]\n",
      "confidence interval for percentage area per class:\n",
      " [2.449942581976087, 0.37266421030865493, 2.4296033021275183]\n"
     ]
    }
   ],
   "source": [
    "# PERCENTAGE OF AREA ESTIMATION\n",
    "# we had calculated the area estimators before, they are used in producer's accuracy\n",
    "print(\"percentage of area per class: \\n\", [x*100 for x in p_hat_dotj])\n",
    "\n",
    "# -------------------------------------\n",
    "# STD ERROR\n",
    "SE_p_hat_dotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ (W[i]**2) * (n[i,j]/n_idot[i]) * (1 -  (n[i,j]/n_idot[i]))/ (n_idot[i]-1) \n",
    "                for i in range(n_classes)]\n",
    "    SE_p_hat_dotj.append(np.sqrt(sum(summands)))\n",
    "    \n",
    "print(\"confidence interval for percentage area per class:\\n\", [x*1.96*100 for x in SE_p_hat_dotj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx area per class (ha): \n",
      " [11302278.810610583, 551348.3897653435, 16427094.167157656]\n",
      "confidence interval for area per class (m^2):\n",
      " [692861.4352732152, 105392.12695391006, 687109.3402110785]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_area = total_pix * (21158/235086)\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (ha): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (m^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx area per class (km^2): \n",
      " [45.20855969040702, 2.205366458091275, 65.70756921150169]\n",
      "confidence interval for area per class (km^2):\n",
      " [2.771411684192743, 0.4215633273726857, 2.748403586682587]\n"
     ]
    }
   ],
   "source": [
    "# in km^2, assuming a resolution of 0.5m per pixel side\n",
    "map_area = total_pix * 0.36 / (1000**2)\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (km^2): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (km^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
