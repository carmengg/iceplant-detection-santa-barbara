{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1359446-7108-4127-9c8f-edab94497645",
   "metadata": {},
   "source": [
    "# About\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc  \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio\n",
    "import rioxarray as rioxr\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "import raster_features as rf\n",
    "\n",
    "# Assuming repository's parent directory is the home directory\n",
    "home = os.path.expanduser(\"~\")\n",
    "os.chdir(os.path.join(home,'iceplant-detection-santa-barbara'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ee69c2-cbeb-4d7c-8907-a49931a06e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to save rasters\n",
    "save_rasters = False\n",
    "prefix = 'final_model'\n",
    "\n",
    "# whether to print processing info at runtime\n",
    "verbose = True\n",
    "save_processing_times = True\n",
    "delete_aux_rasters = True\n",
    "\n",
    "# **************************************************************\n",
    "clip = True\n",
    "\n",
    "# **************************************************************\n",
    "# whether only to process aois\n",
    "only_aois = True\n",
    "\n",
    "# **************************************************************\n",
    "# radius of the disk (in pixels) over which entropy is calculated\n",
    "entropy_r = 6\n",
    "\n",
    "# features for snow13\n",
    "feature_order = ['r', 'r_avg13', 'r_entr13', \n",
    "                 'g', 'g_avg13', 'g_entr13', \n",
    "                 'b', 'b_avg13', 'b_entr13', \n",
    "                 'nir', 'nir_avg13', 'nir_entr13', \n",
    "                 'ndvi', 'ndvi_avg13', 'ndvi_entr13', \n",
    "                 'month', 'day_in_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b6fc66-a393-4f8d-96e4-f75a9b77104e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# length of side of the square window over which average/max/min are calculated.\n",
    "box_side = entropy_r *2 +1\n",
    "\n",
    "# **************************************************************\n",
    "# open shapefile of SB coastal buffer and process it to use it for clipping\n",
    "\n",
    "coast = gpd.read_file(os.path.join(os.getcwd(), \n",
    "                                   'data',\n",
    "                                   'shapefiles',\n",
    "                                   'SB_coastal_buffer', \n",
    "                                   'SB_coastal_buffer.shp'))\n",
    "coast_geo = coast.geometry.apply(mapping)\n",
    "\n",
    "# **************************************************************\n",
    "# load pre-trained random forest classifier\n",
    "model_fp = os.path.join(os.getcwd(),\n",
    "                  'code',\n",
    "                  'B_model_training',\n",
    "                  'final_model.joblib')\n",
    "rfc = load(model_fp) \n",
    "\n",
    "# **************************************************************\n",
    "\n",
    "if only_aois:\n",
    "    scene_ids = ['ca_m_3412037_nw_10_060_20200607',\n",
    "                 'ca_m_3412039_nw_10_060_20200522']#,\n",
    "               #  'ca_m_3412040_ne_10_060_20200522',\n",
    "               #  'ca_m_3411934_sw_11_060_20200521',\n",
    "               #  'ca_m_3411936_se_11_060_20200521']\n",
    "else:    \n",
    "    # select the scene ids from given year that intersect the coastal buffer\n",
    "    # the itemids of all scenes that intersect the coast were previously stored in a csv\n",
    "    scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                         'data',\n",
    "                                         'NAIP_ids',\n",
    "                                         'NAIP_2020_SB_coastal_scenes_ids.csv'))\n",
    "    scene_ids = scene_ids.itemid\n",
    "\n",
    "# **************************************************************\n",
    "# prepare folder to save rasters\n",
    "if save_rasters:\n",
    "    out_dir = os.path.join(os.getcwd(),\n",
    "                      'data',\n",
    "                      'map',\n",
    "                      'processing_results')\n",
    "    if os.path.exists(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    out_dir = os.path.join(out_dir, prefix+'_preds_on_scenes')\n",
    "    if os.path.exists(out_dir) == False:\n",
    "        os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5307353a-4d65-486c-9c39-fc7fd36fb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected data on scene\n",
      "selected vegetation pixels\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/xarray/core/duck_array_ops.py:188: RuntimeWarning: invalid value encountered in cast\n",
      "  return data.astype(dtype, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created/verified NDVI auxiliary rasters (avgs,entr)\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "/home/jovyan/iceplant-detection-santa-barbara/code/C_map_creation/temp/r_ca_m_3412037_nw_10_060_20200607_avgs.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/xarray/backends/file_manager.py:210\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<function open at 0x7f04359b9f80>, ('/home/jovyan/iceplant-detection-santa-barbara/code/C_map_creation/temp/r_ca_m_3412037_nw_10_060_20200607_avgs.tif',), 'r', (('sharing', False),), 'b87386af-97d6-4645-b08d-8c3059818b66']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:221\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:221\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /home/jovyan/iceplant-detection-santa-barbara/code/C_map_creation/temp/r_ca_m_3412037_nw_10_060_20200607_avgs.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 167\u001b[0m\n\u001b[1;32m    165\u001b[0m window_values \u001b[38;5;241m=\u001b[39m []    \n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fp_aux \u001b[38;5;129;01min\u001b[39;00m window_fps:\n\u001b[0;32m--> 167\u001b[0m     match \u001b[38;5;241m=\u001b[39m \u001b[43mrioxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_rasterio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_aux\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    168\u001b[0m     match_vector \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(match\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    169\u001b[0m     window_values\u001b[38;5;241m.\u001b[39mappend(match_vector)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/rioxarray/_io.py:1124\u001b[0m, in \u001b[0;36mopen_rasterio\u001b[0;34m(filename, parse_coordinates, chunks, cache, lock, masked, mask_and_scale, variable, group, default_name, decode_times, decode_timedelta, band_as_variable, **open_kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1123\u001b[0m         manager \u001b[38;5;241m=\u001b[39m URIManager(file_opener, filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mopen_kwargs)\n\u001b[0;32m-> 1124\u001b[0m     riods \u001b[38;5;241m=\u001b[39m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m     captured_warnings \u001b[38;5;241m=\u001b[39m rio_warnings\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# raise the NotGeoreferencedWarning if applicable\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/xarray/backends/file_manager.py:192\u001b[0m, in \u001b[0;36mCachingFileManager.acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Acquire a file object from the manager.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    A new file is only opened if it has expired from the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m        An open file object, as returned by ``opener(*args, **kwargs)``.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     file, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/xarray/backends/file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    215\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 216\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: /home/jovyan/iceplant-detection-santa-barbara/code/C_map_creation/temp/r_ca_m_3412037_nw_10_060_20200607_avgs.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "def clear_screen():\n",
    "    if os.name in ('nt', 'dos'):\n",
    "        _ = os.system('cls')\n",
    "    elif os.name == 'posix':\n",
    "        _ = os.system('clear')\n",
    "        \n",
    "# ---------------------------------------\n",
    "# temp directory\n",
    "\n",
    "temp_dir = os.path.join(os.getcwd(),\n",
    "                        'code',\n",
    "                        'C_map_creation',\n",
    "                        'temp')\n",
    "if os.path.exists(temp_dir) == False:\n",
    "    os.mkdir(temp_dir)\n",
    "# ---------------------------------------\n",
    "# collect processing information for each scene\n",
    "times_access = []\n",
    "times_pre = []\n",
    "times_features = []\n",
    "times_class = []\n",
    "times_post = []\n",
    "processed = []\n",
    "reason = []\n",
    "veg_pixels = [] # number of pixels with ndwi<0.3 and ndwi>0.05\n",
    "n_pixels = []   # number of non-zero pixels in masked scene\n",
    "\n",
    "# counter for scenes queued for processing\n",
    "N = len(scene_ids)\n",
    "\n",
    "# total time initial point\n",
    "t_total = time.time()\n",
    "\n",
    "# ---------------------------------------\n",
    "# ---------------------------------------\n",
    "\n",
    "for itemid in scene_ids:    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** DATA ACCESS ****************************************\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "    raster = rf.rioxr_from_itemid(itemid)\n",
    "    times_access.append(time.time()-t0)\n",
    "    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** PRE-PROCESSING ****************************************\n",
    "    t0 = time.time()\n",
    "    if clip:\n",
    "        raster = raster.rio.clip(coast_geo, coast.crs)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select pixels with data (blacked out portions have 0 on all bands)\n",
    "    df = rf.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "    n_pixels.append(df.shape[0])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stop if there's no data at intersection\n",
    "    if df.shape[0] == 0:\n",
    "        times_pre.append(time.time()-t0)\n",
    "        rf.finish_processing('no_data', processed, reason, \n",
    "                             times_features, times_class, times_post, \n",
    "                             veg_pixels, itemid)\n",
    "        if verbose:\n",
    "            rf.finish_processing_message('no_data', itemid)\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep indices of water and low-ndvi pixels\n",
    "        # add ndvi and ndwi features for each pixel\n",
    "        if verbose:\n",
    "            print('selected data on scene')\n",
    "        \n",
    "        is_veg, water_index, not_veg_index = rf.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "      # ---------------------------------------\n",
    "        # stop if there are no vegetation pixels at intersection\n",
    "        if is_veg.shape[0] == 0:\n",
    "            times_pre.append(time.time()-t0)            \n",
    "            rf.finish_processing('no_veg', processed, reason, \n",
    "                                 times_features, times_class, times_post, \n",
    "                                 veg_pixels, itemid)            \n",
    "            if verbose:\n",
    "                rf.finish_processing_message('no_veg', itemid)\n",
    "\n",
    "        else:\n",
    "            times_pre.append(time.time()-t0)\n",
    "            processed.append('Y')\n",
    "            reason.append('processed')\n",
    "            if verbose:\n",
    "                print('selected vegetation pixels')\n",
    "    # **************************************************************************************\n",
    "    # ******************************** START CREATING FEATURES *****************************            \n",
    "            t0 = time.time()          \n",
    "            # ---------------------------------------\n",
    "            # discard ndwi and add date features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = rf.add_date_features(is_veg, \n",
    "                                          rf.rioxr_from_itemid(itemid).datetime)\n",
    "\n",
    "\n",
    "    # *************************************************************************************************\n",
    "    # ******************************** CREATE R,G,B,NIR AUXILIARY RASTERS *****************************\n",
    "            # make auxiliary spectral rasters from clipped NAIP \n",
    "            band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "            tags = ['_avgs', '_entrs']\n",
    "            window_fps = []\n",
    "            window_cols = []\n",
    "\n",
    "            for name, band in zip(band_names,range(1,5)):\n",
    "                rast_name = name+itemid\n",
    "                \n",
    "                for tag in tags:\n",
    "                    rast_fp = os.path.join(temp_dir, rast_name + tag + '.tif')\n",
    "                    window_fps.append(rast_fp)        \n",
    "                    window_cols.append(name.replace('_','')+tag.replace('s',str(box_side)))\n",
    "                    \n",
    "                    if os.path.isfile(rast_fp) == False:\n",
    "                        if tag == '_avgs':\n",
    "                            rf.avg_raster(raster=raster, band=band, rast_name=rast_name, n=box_side, folder_path=temp_dir)                            \n",
    "                        elif tag == '_entrs':\n",
    "                            rf.entropy_raster(raster=raster, band=band, rast_name=rast_name, n=entropy_r, folder_path=temp_dir)\n",
    "                \n",
    "            if verbose:\n",
    "                print('created/verified R,G,B,NIR auxiliary rasters (avgs, entr)')\n",
    "\n",
    "\n",
    "    # ********************************************************************************************\n",
    "    # ******************************** CREATE NDVI AUXILIARY RASTERS *****************************\n",
    "            ndvi = rf.ndvi_xarray(raster)\n",
    "            band_names.append('ndvi_')\n",
    "            rast_name = 'ndvi_'+itemid\n",
    "\n",
    "            for tag in tags:\n",
    "                rast_fp = os.path.join(temp_dir, rast_name + tag + '.tif')\n",
    "                window_fps.append(rast_fp)        \n",
    "                window_cols.append('ndvi' + tag.replace('s',str(box_side)))                \n",
    "\n",
    "                if os.path.isfile(rast_fp) == False:\n",
    "                    if tag == '_avgs':\n",
    "                        rf.avg_raster(rast_data=ndvi, \n",
    "                                      crs=raster.rio.crs, \n",
    "                                      transf=raster.rio.transform(), \n",
    "                                      rast_name=rast_name, \n",
    "                                      n=box_side,\n",
    "                                      folder_path=temp_dir)\n",
    "                    elif tag == '_entrs':\n",
    "                        # adjusting to entropy input types\n",
    "                        ndvi = ndvi*100+100  \n",
    "                        rf.entropy_raster(rast_data=ndvi.astype('uint8'), \n",
    "                                          crs=raster.rio.crs, \n",
    "                                          transf=raster.rio.transform(), \n",
    "                                          rast_name=rast_name, \n",
    "                                          n=entropy_r,\n",
    "                                          folder_path=temp_dir)\n",
    "            if verbose:\n",
    "                print('created/verified NDVI auxiliary rasters (avgs,entr)')\n",
    "            #free memory\n",
    "            del ndvi\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "    # *******************************************************************************************\n",
    "    # *********************** EXTRACT FEATURES FROM AUXILIARY RASTERS ***************************\n",
    "            window_values = []    \n",
    "            for fp_aux in window_fps:\n",
    "                match = rioxr.open_rasterio(fp_aux).squeeze()\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                window_values.append(match_vector)\n",
    "                if delete_aux_rasters:\n",
    "                    os.remove(fp_aux)\n",
    "\n",
    "            df_window = pd.DataFrame(dict(zip( window_cols, window_values)))\n",
    "\n",
    "            scene_features = pd.concat([is_veg, df_window.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "            # **********************************************************************************************\n",
    "            # *************** REMOVE NA VALUES (PIXELS AT EDGE OF CLIPPED PART OF RASTER) ******************\n",
    "            # combine indices for r_min == 0 and ndvi_min == nan, ndvi_avg == nan\n",
    "\n",
    "            remove = set()\n",
    "            for band in [x.replace('s',str(box_side)) for x in ['ndvi'+ y for y in tags]]:\n",
    "                remove = remove.union(scene_features[band][scene_features[band].isna() == True].index)\n",
    "            # remove these indices from scene_features\n",
    "            # no need to add them anywhere else, they will be part of the raster's background\n",
    "            scene_features = scene_features.drop(remove)\n",
    "\n",
    "            #free memory            \n",
    "            del df_window, window_values, match_vector, match, remove\n",
    "            gc.collect()  \n",
    "\n",
    "            # ******************************************************************************\n",
    "            # ******************************** ORDER FEATURES ****************************** \n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "            times_features.append(time.time()-t0)            \n",
    "            if verbose:\n",
    "                print('finished assembling features')\n",
    "\n",
    "            # ***********************************************************************************************\n",
    "            # *************************************** CLASSIFICATION ****************************************\n",
    "            t0 = time.time()             \n",
    "            scene_preds = rfc.predict(np.array(scene_features))\n",
    "\n",
    "            # ---------------------------------------\n",
    "\n",
    "            #preds = scene_preds.compute()\n",
    "            preds = scene_preds\n",
    "            \n",
    "            times_class.append(time.time() - t0)            \n",
    "            if verbose:\n",
    "                print('finished classification')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** POST-PROCESSING ****************************************\n",
    "            t0 = time.time()            \n",
    "            # recover pixel indices for iceplant classifications\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # reconstruct indices into image\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            reconstruct = rf.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "\n",
    "            # ---------------------------------------\n",
    "\n",
    "            times_post.append(time.time() - t0)\n",
    "            if verbose:\n",
    "                print('finished post-processing')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** SAVE RASTERS *******************************************  \n",
    "            if save_rasters:\n",
    "                filename = prefix+'_preds_' + itemid + '.tif'\n",
    "\n",
    "                with rasterio.open(\n",
    "                    os.path.join(out_dir, filename),  # file path\n",
    "                    'w',           # w = write\n",
    "                    driver = 'GTiff', # format\n",
    "                    height = reconstruct.shape[0], \n",
    "                    width = reconstruct.shape[1],\n",
    "                    count = 1,  # number of raster bands in the dataset\n",
    "                    dtype = rasterio.uint8,\n",
    "                    crs = raster.rio.crs,\n",
    "                    transform = raster.rio.transform(),\n",
    "                ) as dst:\n",
    "                    dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "\n",
    "            if verbose:\n",
    "                print('FINISHED: ', itemid)        \n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # ************************************ FINAL INFO MESSAGE ***************************************            \n",
    "    N = N-1        \n",
    "    if verbose:\n",
    "        print('REMAINING: ', N, 'scenes', '\\n')\n",
    "    clear_screen()\n",
    "\n",
    "total_time = time.time() - t_total\n",
    "print('TOTAL TIME: ', (total_time)/60, ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba01554-43d4-4786-9d91-60712362ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save times processed and itemids as dataframe\n",
    "D = { 'itemid': scene_ids,\n",
    "     'processed': processed,\n",
    "     'reason':reason,\n",
    "     'access_times': times_access,\n",
    "     'pre_times': times_pre,\n",
    "     'fts_times': times_features,\n",
    "     'class_times' : times_class,\n",
    "     'post_times' : times_post, \n",
    "     'processed_pix' : n_pixels }\n",
    "processing_df = pd.DataFrame(D)\n",
    "\n",
    "if save_processing_times:\n",
    "    fp = os.path.join(os.getcwd(),'processing_results')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "\n",
    "    filename = prefix+'_processing_results.csv'\n",
    "\n",
    "    processing_df.to_csv(os.path.join(fp, filename ), index=False)\n",
    "\n",
    "with open(\"TOTAL_TIME.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"Total time \" + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc05e01-4a42-4c9e-827a-518f4cf41dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
