{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1359446-7108-4127-9c8f-edab94497645",
   "metadata": {},
   "source": [
    "# About\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc  \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import rasterio\n",
    "import rioxarray as rioxr\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "import raster_features as rf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Assuming repository's parent directory is the home directory\n",
    "home = os.path.expanduser(\"~\")\n",
    "os.chdir(os.path.join(home,'iceplant-detection-santa-barbara'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ee69c2-cbeb-4d7c-8907-a49931a06e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to save rasters\n",
    "save_rasters = True\n",
    "prefix = 'final_model'\n",
    "\n",
    "# whether to print processing info at runtime\n",
    "verbose = True\n",
    "save_processing_times = True\n",
    "delete_aux_rasters = False\n",
    "\n",
    "# **************************************************************\n",
    "clip = True\n",
    "\n",
    "# **************************************************************\n",
    "# whether only to process aois\n",
    "only_aois = True\n",
    "\n",
    "# **************************************************************\n",
    "# radius of the disk (in pixels) over which entropy is calculated\n",
    "entropy_r = 6\n",
    "\n",
    "# features for snow13\n",
    "feature_order = ['r', 'r_avg13', 'r_entr13', \n",
    "                 'g', 'g_avg13', 'g_entr13', \n",
    "                 'b', 'b_avg13', 'b_entr13', \n",
    "                 'nir', 'nir_avg13', 'nir_entr13', \n",
    "                 'ndvi', 'ndvi_avg13', 'ndvi_entr13', \n",
    "                 'month', 'day_in_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b6fc66-a393-4f8d-96e4-f75a9b77104e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# length of side of the square window over which average/max/min are calculated.\n",
    "box_side = entropy_r *2 +1\n",
    "\n",
    "# **************************************************************\n",
    "# open shapefile of SB coastal buffer and process it to use it for clipping\n",
    "\n",
    "coast = gpd.read_file(os.path.join(os.getcwd(), \n",
    "                                   'data',\n",
    "                                   'shapefiles',\n",
    "                                   'SB_coastal_buffer', \n",
    "                                   'SB_coastal_buffer.shp'))\n",
    "# greate GeoJSON to clip raster with it\n",
    "coast_geo = coast.geometry.apply(mapping)\n",
    "\n",
    "# **************************************************************\n",
    "# load pre-trained random forest classifier\n",
    "model_fp = os.path.join(os.getcwd(),\n",
    "                  'code',\n",
    "                  'B_model_training',\n",
    "                  'final_model.joblib')\n",
    "rfc = load(model_fp) \n",
    "\n",
    "# **************************************************************\n",
    "\n",
    "if only_aois:\n",
    "    scene_ids = ['ca_m_3412037_nw_10_060_20200607',\n",
    "                 'ca_m_3412039_nw_10_060_20200522']#,\n",
    "               #  'ca_m_3412040_ne_10_060_20200522',\n",
    "               #  'ca_m_3411934_sw_11_060_20200521',\n",
    "               #  'ca_m_3411936_se_11_060_20200521']\n",
    "else:    \n",
    "    # select the scene ids from given year that intersect the coastal buffer\n",
    "    # the itemids of all scenes that intersect the coast were previously stored in a csv\n",
    "    scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                         'data',\n",
    "                                         'NAIP_ids',\n",
    "                                         'NAIP_2020_SB_coastal_scenes_ids.csv'))\n",
    "    scene_ids = scene_ids.itemid\n",
    "\n",
    "# **************************************************************\n",
    "# prepare folder to save rasters\n",
    "if save_rasters:\n",
    "    out_dir = os.path.join(os.getcwd(),\n",
    "                      'data',\n",
    "                      'map',\n",
    "                      'processing_results')\n",
    "    if os.path.exists(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    out_dir = os.path.join(out_dir, prefix+'_preds_on_scenes')\n",
    "    if os.path.exists(out_dir) == False:\n",
    "        os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead5a15d-e2d3-44da-b862-8de3fdd0ebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME:  2.849415071805318  mins\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# temp directory\n",
    "\n",
    "temp_dir = os.path.join(os.getcwd(),\n",
    "                        'code',\n",
    "                        'C_map_creation',\n",
    "                        'temp')\n",
    "if os.path.exists(temp_dir) == False:\n",
    "    os.mkdir(temp_dir)\n",
    "# ---------------------------------------\n",
    "# collect processing information for each scene\n",
    "times_access = []\n",
    "times_pre = []\n",
    "times_features = []\n",
    "times_class = []\n",
    "times_post = []\n",
    "processed = []\n",
    "reason = []\n",
    "veg_pixels = [] # number of pixels with ndwi<0.3 and ndwi>0.05\n",
    "n_pixels = []   # number of non-zero pixels in masked scene\n",
    "\n",
    "# counter for scenes queued for processing\n",
    "N = len(scene_ids)\n",
    "\n",
    "# total time initial point\n",
    "t_total = time.time()\n",
    "\n",
    "# ---------------------------------------\n",
    "# ---------------------------------------\n",
    "\n",
    "for itemid in scene_ids:    \n",
    "    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** DATA ACCESS ****************************************\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "    raster = rf.rioxr_from_itemid(itemid)\n",
    "    times_access.append(time.time()-t0)\n",
    "\n",
    "    # *data******************************************************************************************\n",
    "    # *************************************** PRE-PROCESSING ****************************************\n",
    "    t0 = time.time()\n",
    "    if clip:\n",
    "        #warnings.simplefilter(\"ignore\")\n",
    "        raster = raster.rio.clip(coast_geo, coast.crs)\n",
    "        #warnings.simplefilter('default')\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select pixels with data (blacked out portions have 0 on all bands)\n",
    "    df = rf.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "    n_pixels.append(df.shape[0])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stop if there's no data at intersection\n",
    "    if df.shape[0] == 0:\n",
    "        times_pre.append(time.time()-t0)\n",
    "        rf.finish_processing('no_data', processed, reason, \n",
    "                             times_features, times_class, times_post, \n",
    "                             veg_pixels, itemid)\n",
    "        if verbose:\n",
    "            rf.finish_processing_message('no_data', itemid)\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep indices of water and low-ndvi pixels\n",
    "        # add ndvi and ndwi features for each pixel\n",
    "        if verbose:\n",
    "            print('selected data on scene')\n",
    "        \n",
    "        is_veg, water_index, not_veg_index = rf.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "      # ---------------------------------------\n",
    "        # stop if there are no vegetation pixels at intersection\n",
    "        if is_veg.shape[0] == 0:\n",
    "            times_pre.append(time.time()-t0)            \n",
    "            rf.finish_processing('no_veg', processed, reason, \n",
    "                                 times_features, times_class, times_post, \n",
    "                                 veg_pixels, itemid)            \n",
    "            if verbose:\n",
    "                rf.finish_processing_message('no_veg', itemid)\n",
    "\n",
    "        else:\n",
    "            times_pre.append(time.time()-t0)\n",
    "            processed.append('Y')\n",
    "            reason.append('processed')\n",
    "            if verbose:\n",
    "                print('selected vegetation pixels')\n",
    "    # **************************************************************************************\n",
    "    # ******************************** START CREATING FEATURES *****************************            \n",
    "            t0 = time.time()          \n",
    "            # ---------------------------------------\n",
    "            # discard ndwi and add date features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = rf.add_date_features(is_veg, \n",
    "                                          rf.rioxr_from_itemid(itemid).datetime)\n",
    "\n",
    "    # *************************************************************************************************\n",
    "    # ******************************** CREATE R,G,B,NIR AUXILIARY RASTERS *****************************\n",
    "            # make auxiliary spectral rasters from clipped NAIP \n",
    "            band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "            tags = ['_avgs', '_entrs']\n",
    "            window_fps = []\n",
    "            window_cols = []\n",
    "\n",
    "            for name, band in zip(band_names,range(1,5)):\n",
    "                rast_name = name+itemid\n",
    "                \n",
    "                for tag in tags:\n",
    "                    rast_fp = os.path.join(temp_dir, rast_name + tag + '.tif')\n",
    "                    window_fps.append(rast_fp)        \n",
    "                    window_cols.append(name.replace('_','')+tag.replace('s',str(box_side)))\n",
    "                    \n",
    "                    if os.path.isfile(rast_fp) == False:\n",
    "                        if tag == '_avgs':\n",
    "                            rf.avg_raster(raster=raster, band=band, rast_name=rast_name, n=box_side, folder_path=temp_dir)                            \n",
    "                        elif tag == '_entrs':\n",
    "                            rf.entropy_raster(raster=raster, band=band, rast_name=rast_name, n=entropy_r, folder_path=temp_dir)\n",
    "                \n",
    "            if verbose:\n",
    "                print('created/verified R,G,B,NIR auxiliary rasters (avgs, entr)')\n",
    "\n",
    "            # ********************************************************************************************\n",
    "            # ******************************** CREATE NDVI AUXILIARY RASTERS *****************************\n",
    "            ndvi = rf.ndvi_xarray(raster)\n",
    "            band_names.append('ndvi_')\n",
    "            rast_name = 'ndvi_'+itemid\n",
    "\n",
    "            for tag in tags:\n",
    "                rast_fp = os.path.join(temp_dir, rast_name + tag + '.tif')\n",
    "                window_fps.append(rast_fp)        \n",
    "                window_cols.append('ndvi' + tag.replace('s',str(box_side)))                \n",
    "\n",
    "                if os.path.isfile(rast_fp) == False:\n",
    "                    if tag == '_avgs':\n",
    "                        rf.avg_raster(rast_data=ndvi, \n",
    "                                      crs=raster.rio.crs, \n",
    "                                      transf=raster.rio.transform(), \n",
    "                                      rast_name=rast_name, \n",
    "                                      n=box_side,\n",
    "                                      folder_path=temp_dir)\n",
    "                    elif tag == '_entrs':\n",
    "                        # adjusting to entropy input types\n",
    "                        ndvi = ndvi*100+100  \n",
    "                        rf.entropy_raster(rast_data=ndvi.astype('uint8'), \n",
    "                                          crs=raster.rio.crs, \n",
    "                                          transf=raster.rio.transform(), \n",
    "                                          rast_name=rast_name, \n",
    "                                          n=entropy_r,\n",
    "                                          folder_path=temp_dir)\n",
    "            if verbose:\n",
    "                print('created/verified NDVI auxiliary rasters (avgs,entr)')\n",
    "            #free memory\n",
    "            del ndvi\n",
    "            gc.collect()\n",
    "\n",
    "    # *******************************************************************************************\n",
    "    # *********************** EXTRACT FEATURES FROM AUXILIARY RASTERS ***************************\n",
    "            window_values = []    \n",
    "            for fp_aux in window_fps:\n",
    "                match = rioxr.open_rasterio(fp_aux).squeeze()\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                window_values.append(match_vector)\n",
    "                if delete_aux_rasters:\n",
    "                    os.remove(fp_aux)\n",
    "\n",
    "            df_window = pd.DataFrame(dict(zip( window_cols, window_values)))\n",
    "\n",
    "            scene_features = pd.concat([is_veg, df_window.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "            # **********************************************************************************************\n",
    "            # *************** REMOVE NA VALUES (PIXELS AT EDGE OF CLIPPED PART OF RASTER) ******************\n",
    "            # combine indices for r_min == 0 and ndvi_min == nan, ndvi_avg == nan\n",
    "\n",
    "            remove = set()\n",
    "            for band in [x.replace('s',str(box_side)) for x in ['ndvi'+ y for y in tags]]:\n",
    "                remove = remove.union(scene_features[band][scene_features[band].isna() == True].index)\n",
    "            # remove these indices from scene_features\n",
    "            # no need to add them anywhere else, they will be part of the raster's background\n",
    "            scene_features = scene_features.drop(remove)\n",
    "\n",
    "            #free memory            \n",
    "            del df_window, window_values, match_vector, match, remove\n",
    "            gc.collect()  \n",
    "\n",
    "            # ******************************************************************************\n",
    "            # ******************************** ORDER FEATURES ****************************** \n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "            times_features.append(time.time()-t0)            \n",
    "            if verbose:\n",
    "                print('finished assembling features')\n",
    "\n",
    "            # ***********************************************************************************************\n",
    "            # *************************************** CLASSIFICATION ****************************************\n",
    "            t0 = time.time()             \n",
    "            scene_preds = rfc.predict(np.array(scene_features))\n",
    "\n",
    "            # ---------------------------------------\n",
    "\n",
    "            #preds = scene_preds.compute()\n",
    "            preds = scene_preds\n",
    "            \n",
    "            times_class.append(time.time() - t0)            \n",
    "            if verbose:\n",
    "                print('finished classification')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** POST-PROCESSING ****************************************\n",
    "            t0 = time.time()            \n",
    "            # recover pixel indices for iceplant classifications\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # reconstruct indices into image\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            reconstruct = rf.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "\n",
    "            # ---------------------------------------\n",
    "\n",
    "            times_post.append(time.time() - t0)\n",
    "            if verbose:\n",
    "                print('finished post-processing')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** SAVE RASTERS *******************************************  \n",
    "            if save_rasters:\n",
    "                filename = prefix+'_preds_' + itemid + '.tif'\n",
    "\n",
    "                with rasterio.open(\n",
    "                    os.path.join(out_dir, filename),  # file path\n",
    "                    'w',           # w = write\n",
    "                    driver = 'GTiff', # format\n",
    "                    height = reconstruct.shape[0], \n",
    "                    width = reconstruct.shape[1],\n",
    "                    count = 1,  # number of raster bands in the dataset\n",
    "                    dtype = rasterio.uint8,\n",
    "                    crs = raster.rio.crs,\n",
    "                    transform = raster.rio.transform(),\n",
    "                ) as dst:\n",
    "                    dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "\n",
    "            if verbose:\n",
    "                print('FINISHED: ', itemid)        \n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # ************************************ FINAL INFO MESSAGE ***************************************            \n",
    "    N = N-1        \n",
    "    if verbose:\n",
    "        print('REMAINING: ', N, 'scenes', '\\n')\n",
    "        clear_output(True)\n",
    "\n",
    "\n",
    "total_time = time.time() - t_total\n",
    "print('FINISH PROCESSING')\n",
    "print('TOTAL TIME: ', (total_time)/60, ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba01554-43d4-4786-9d91-60712362ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save times processed and itemids as dataframe\n",
    "D = { 'itemid': scene_ids,\n",
    "     'processed': processed,\n",
    "     'reason':reason,\n",
    "     'access_times': times_access,\n",
    "     'pre_times': times_pre,\n",
    "     'fts_times': times_features,\n",
    "     'class_times' : times_class,\n",
    "     'post_times' : times_post, \n",
    "     'processed_pix' : n_pixels }\n",
    "processing_df = pd.DataFrame(D)\n",
    "\n",
    "if save_processing_times:\n",
    "\n",
    "    filename = prefix+'_processing_results.csv'\n",
    "\n",
    "    processing_df.to_csv(os.path.join(out_dir, filename ), index=False)\n",
    "\n",
    "with open(os.path.join(out_dir,\"TOTAL_TIME.txt\"), \"w\") as text_file:\n",
    "    text_file.write(\"Total time \" + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f3882-90ef-47d2-b915-b908f9abc0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
